{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "from src.settings import StyleSettings\n",
    "from src.data.data_tools import StyleDataset\n",
    "import numpy as np\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = StyleSettings()\n",
    "traindataset = StyleDataset([settings.trainpath])\n",
    "testdataset = StyleDataset([settings.testpath])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 419 batches in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traindataset) // 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Lace is an openwork fabric , patterned with open holes in the work , made by machine or by hand.',\n",
       " 'wiki')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = traindataset[42]\n",
    "x, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every batch is a `Tuple[str, str]` of a sentence and a label. We can see this is a classification task.\n",
    "The task is, to classify sentences in four categories.\n",
    "Lets build a vocabulary by copy-pasting the code we used before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-05 18:23:48.534 | INFO     | src.models.tokenizer:build_vocab:27 - Found 19306 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19308"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models import tokenizer\n",
    "\n",
    "corpus = []\n",
    "for i in range(len(traindataset)):\n",
    "    x = tokenizer.clean(traindataset[i][0])\n",
    "    corpus.append(x)\n",
    "v = tokenizer.build_vocab(corpus, max=20000)\n",
    "len(v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to cast the labels to an integers. You can use this dictionary to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\"humor\": 0, \"reuters\": 1, \"wiki\": 2, \"proverbs\": 3}\n",
    "d[y]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Figure out, for every class, what accuracy you should expect if the model would guess blind on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ~ about 4 lines of code\n",
    "\n",
    "incorrect = [0,0,0,0]\n",
    "correct = [0,0,0,0]\n",
    "\n",
    "for x,y in traindataset:\n",
    "    if d[y] == np.random.randint(4):\n",
    "        correct [d[y]] = correct[d[y]] + 1\n",
    "    else:\n",
    "        incorrect [d[y]] = incorrect [d[y]] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class humor (0)\n",
      "Accuracy: 25%\n",
      "1070 correct van 4213 totaal\n",
      "Populatie 31% van totaal traindataset\n",
      "\n",
      "Class reuters (1)\n",
      "Accuracy: 25%\n",
      "1061 correct van 4186 totaal\n",
      "Populatie 31% van totaal traindataset\n",
      "\n",
      "Class wiki (2)\n",
      "Accuracy: 24%\n",
      "1037 correct van 4181 totaal\n",
      "Populatie 31% van totaal traindataset\n",
      "\n",
      "Class proverbs (3)\n",
      "Accuracy: 23%\n",
      "196 correct van 831 totaal\n",
      "Populatie 6% van totaal traindataset\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for Class in d:\n",
    "    populatie_class = int(correct[d[Class]]) + int(incorrect[d[Class]])\n",
    "    populatie_perc_totaal = int((populatie_class / len(traindataset))*100)\n",
    "    accuracy = int(correct[d[Class]] / populatie_class * 100)\n",
    "\n",
    "    print(f\"Class {Class} ({d[Class]})\")\n",
    "    print(f\"Accuracy: {accuracy}%\") \n",
    "    print(f\"{correct[d[Class]]} correct van {populatie_class} totaal\") \n",
    "    print(f\"Populatie {populatie_perc_totaal}% van totaal traindataset\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reflect on what you see. What does this mean? What implications does this have? Why is that good/bad?\n",
    "Are there things down the line that could cause a problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wat zie ik?\n",
      "De accuracy is voor alle classes ongeveer gelijk, tussen de 22% en 25%\n",
      "De classes humor, reuters hen wiki hebben allemaal ongeveer een gelijk deel in de trainingsset, namelijk 31%\n",
      "Terwijl proverbs significant kleiner is, namelijk 7%\n",
      "\n",
      "Wat betekent dat?\n",
      "Een ongebalanceerde trainset kan er voor zorgen dat je model slecht gaat presteren.\n",
      "Het kan lijken alsof het model goed presteert, terwijl deze eigenlijk aan het overfitten is.\n",
      "De class 'proverbs' is maar een klein deel van de totaal trainingset\n",
      "terwijl dit in werkelijkheid op de testset veel groter deel kan zijn, maar het model is hier niet op getraind\n",
      "\n",
      "Hoe kan je het oplossen\n",
      "bijvoorbeeld:\n",
      "1. Sampelen van datapunten, zodat de trainset toch nog een gelijke populatie krijgt\n",
      "2. gewichten toevoegen , bijv. random forest\n",
      "\n",
      "Als er geen manier is om het op te lossen, dan is accuracy niet het goede instrument om te meten hoe het model presteert\n"
     ]
    }
   ],
   "source": [
    "print(\"Wat zie ik?\")\n",
    "print(\"De accuracy is voor alle classes ongeveer gelijk, tussen de 22% en 25%\")\n",
    "print(\"De classes humor, reuters hen wiki hebben allemaal ongeveer een gelijk deel in de trainingsset, namelijk 31%\")\n",
    "print(\"Terwijl proverbs significant kleiner is, namelijk 7%\")\n",
    "print(\"\")\n",
    "print(\"Wat betekent dat?\")\n",
    "print(\"Een ongebalanceerde trainset kan er voor zorgen dat je model slecht gaat presteren.\")\n",
    "print(\"Het kan lijken alsof het model goed presteert, terwijl deze eigenlijk aan het overfitten is.\")\n",
    "print(\"De class 'proverbs' is maar een klein deel van de totaal trainingset\")\n",
    "print(\"terwijl dit in werkelijkheid op de testset veel groter deel kan zijn, maar het model is hier niet op getraind\")\n",
    "print(\"\")\n",
    "print(\"Hoe kan je het oplossen\")\n",
    "print(\"bijvoorbeeld:\")\n",
    "print(\"1. Sampelen van datapunten, zodat de trainset toch nog een gelijke populatie krijgt\")\n",
    "print(\"2. gewichten toevoegen , bijv. random forest\")\n",
    "print(\"\")\n",
    "print(\"Als er geen manier is om het op te lossen, dan is accuracy niet het goede instrument om te meten hoe het model presteert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 : Implement a preprocessor\n",
    "\n",
    "We can inherit from `tokenizer.Preprocessor`\n",
    "Only thing we need to adjust is the `cast_label` function.\n",
    " \n",
    "- create a StylePreprocessor class\n",
    "- inherit from Preprocessor\n",
    "- create a new cast_label function for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ~ about 4 lines of code\n",
    "class StylePreprocessor(tokenizer.Preprocessor):\n",
    "    def cast_label(self, label: str) -> int:\n",
    "        d = {\"humor\": 0, \"reuters\": 1, \"wiki\": 2, \"proverbs\": 3}\n",
    "        label_int = d[label]\n",
    "        return label_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the preprocessor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tekst x : Taylor wins by one shot at Pebble Beach  \n",
      "Label y : reuters\n",
      "Na preprocessing: tensor([[4929,  854,   32,   15,  499,   21, 8496,  890]], dtype=torch.int32)\n",
      "Na preprocessing: tensor([1])\n"
     ]
    }
   ],
   "source": [
    "preprocessor = StylePreprocessor(max=100, vocab=v, clean=tokenizer.clean)\n",
    "x1, y1 = preprocessor([(x, y)])\n",
    "\n",
    "print(\"Tekst x :\" , x)\n",
    "print(\"Label y :\", y)\n",
    "print(\"Na preprocessing:\", x1)\n",
    "print(\"Na preprocessing:\", y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the model\n",
    "We can re-use the BaseDatastreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import data_tools\n",
    "\n",
    "trainstreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=traindataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()\n",
    "teststreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=testdataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 24]),\n",
       " tensor([2, 1, 1, 0, 1, 0, 2, 1, 2, 1, 0, 1, 1, 3, 2, 0, 2, 2, 1, 0, 0, 3, 3, 3,\n",
       "         0, 2, 0, 0, 1, 3, 1, 0]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(trainstreamer)\n",
    "x.shape, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 : Metrics, loss\n",
    "Select proper metrics and a loss function.\n",
    "\n",
    "Bonus: implement an additional metric function that is relevant for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import metrics\n",
    "import torch\n",
    "# TODO ~ 2 lines of code\n",
    "\n",
    "metrics = [metrics.F1Score(), metrics.Precision(), metrics.Recall()]\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#Metrics toegevoegd aan src/models/metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 : Basemodel\n",
    "Create a base model. It does not need to be naive; you could re-use the\n",
    "NLP models we used for the IMDB.\n",
    "\n",
    "I suggest to start with a hidden size of about 128.\n",
    "Use a config dictionary, or a gin file, both are fine.\n",
    "\n",
    "Bonus points if you create a Trax model in src.models, and even more if you add a trax training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPmodel(\n",
      "  (emb): Embedding(19308, 128)\n",
      "  (rnn): GRU(128, 128, num_layers=3, batch_first=True, dropout=0.1)\n",
      "  (linear): Linear(in_features=128, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "log_dir = settings.log_dir\n",
    "# TODO between 2 and 8 lines of code, depending on your setup\n",
    "# Assuming you load your model in one line of code from src.models.rnn\n",
    "#model = None\n",
    "#--------------------------------------------\n",
    "\n",
    "from src.models import rnn\n",
    "\n",
    "config = {\n",
    "    \"vocab\": len(v),\n",
    "    \"input_size\": 32,\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 3,\n",
    "    \"dropout\": 0.1,\n",
    "    \"output_size\": 4,\n",
    "}\n",
    "\n",
    "model = rnn.NLPmodel(config)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the trainloop.\n",
    "\n",
    "- Give the lenght of the traindataset, how many batches of 32 can you get out of it?\n",
    "- If you take a short amount of train_steps (eg 25) for every epoch, how many epochs do you need to cover the complete dataset?\n",
    "- What amount of epochs do you need to run the loop with trainsteps=25 to cover the complete traindataset once? \n",
    "- answer the questions above, and pick a reasonable epoch lenght\n",
    "\n",
    "Start with a default learning_rate of 1e-3 and an Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geef de lengte van de traindataset, hoeveel batches van 32 an je hier uit krijgen?\n",
      "Lengte traindataset: 13411\n",
      "Dat is aantal batches van 32:  13411 / 32 = 419.09375 = 420\n",
      "\n",
      "Als je een klein aantal train_steps (bv 25) neemt voor elke epoch, hoeveel epochs moet je nemen om de gehele dataset de tekken?\n",
      "1 epoch is 1 iteratie van de gehele dataset\n",
      "Bij train_stept = 25 , dan heb je minimaal  16.8 epochs nodig om de hele trainingset te doorlopen\n",
      "\n",
      "Hoeveel epochs moet je hebben om de hele dataset 1 keer door te lopen, met trainsteps=25\n",
      "17\n",
      "Keuze voor basemodel aantal epochs = 50\n"
     ]
    }
   ],
   "source": [
    "print(\"Geef de lengte van de traindataset, hoeveel batches van 32 an je hier uit krijgen?\")\n",
    "print(\"Lengte traindataset:\" , len(traindataset))\n",
    "print(\"Dat is aantal batches van 32: \" , len(traindataset), \"/ 32 =\" , len(traindataset)/32 , \"=\" , int(len(traindataset)/32)+1)\n",
    "print(\"\")\n",
    "print(\"Als je een klein aantal train_steps (bv 25) neemt voor elke epoch, hoeveel epochs moet je nemen om de gehele dataset de tekken?\")\n",
    "print(\"1 epoch is 1 iteratie van de gehele dataset\")\n",
    "print(\"Bij train_stept = 25 , dan heb je minimaal \" , (int(len(traindataset)/32)+1)/25 , \"epochs nodig om de hele trainingset te doorlopen\")\n",
    "print(\"\")\n",
    "print(\"Hoeveel epochs moet je hebben om de hele dataset 1 keer door te lopen, met trainsteps=25\")\n",
    "print(\"17\")\n",
    "\n",
    "print(\"Keuze voor basemodel aantal epochs = 50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-05 20:21:26.387 | INFO     | src.data.data_tools:dir_add_timestamp:68 - Logging to ../tune/20220705-2021\n",
      "100%|██████████| 25/25 [00:02<00:00, 10.19it/s]\n",
      "2022-07-05 20:21:29.402 | INFO     | src.training.train_model:trainloop:164 - Epoch 0 train 0.0223 test 0.6520 metric ['0.8061', '0.8149', '0.8494']\n",
      "100%|██████████| 25/25 [00:02<00:00, 12.48it/s]\n",
      "2022-07-05 20:21:31.869 | INFO     | src.training.train_model:trainloop:164 - Epoch 1 train 0.0626 test 0.3925 metric ['0.8420', '0.8897', '0.8627']\n",
      "100%|██████████| 25/25 [00:01<00:00, 13.73it/s]\n",
      "2022-07-05 20:21:34.080 | INFO     | src.training.train_model:trainloop:164 - Epoch 2 train 0.0332 test 0.4312 metric ['0.8323', '0.8413', '0.8698']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.88it/s]\n",
      "2022-07-05 20:21:35.922 | INFO     | src.training.train_model:trainloop:164 - Epoch 3 train 0.0105 test 0.4208 metric ['0.8082', '0.8331', '0.8765']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.97it/s]\n",
      "2022-07-05 20:21:37.725 | INFO     | src.training.train_model:trainloop:164 - Epoch 4 train 0.0232 test 0.4476 metric ['0.8542', '0.8804', '0.8884']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.45it/s]\n",
      "2022-07-05 20:21:39.652 | INFO     | src.training.train_model:trainloop:164 - Epoch 5 train 0.0236 test 0.4999 metric ['0.8240', '0.8555', '0.8601']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.91it/s]\n",
      "2022-07-05 20:21:41.487 | INFO     | src.training.train_model:trainloop:164 - Epoch 6 train 0.0046 test 0.3985 metric ['0.8403', '0.8719', '0.8926']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.18it/s]\n",
      "2022-07-05 20:21:43.283 | INFO     | src.training.train_model:trainloop:164 - Epoch 7 train 0.0044 test 0.4545 metric ['0.8496', '0.8514', '0.8837']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.26it/s]\n",
      "2022-07-05 20:21:45.049 | INFO     | src.training.train_model:trainloop:164 - Epoch 8 train 0.0108 test 0.5557 metric ['0.8467', '0.8494', '0.8958']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.53it/s]\n",
      "2022-07-05 20:21:46.679 | INFO     | src.training.train_model:trainloop:164 - Epoch 9 train 0.0300 test 0.4303 metric ['0.8575', '0.8670', '0.8833']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.43it/s]\n",
      "2022-07-05 20:21:48.459 | INFO     | src.training.train_model:trainloop:164 - Epoch 10 train 0.0139 test 0.4997 metric ['0.8123', '0.8439', '0.8335']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.39it/s]\n",
      "2022-07-05 20:21:50.220 | INFO     | src.training.train_model:trainloop:164 - Epoch 11 train 0.0269 test 0.5304 metric ['0.8452', '0.8499', '0.8834']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.85it/s]\n",
      "2022-07-05 20:21:52.036 | INFO     | src.training.train_model:trainloop:164 - Epoch 12 train 0.0311 test 0.4568 metric ['0.8557', '0.8739', '0.8901']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.64it/s]\n",
      "2022-07-05 20:21:53.889 | INFO     | src.training.train_model:trainloop:164 - Epoch 13 train 0.0140 test 0.5385 metric ['0.8082', '0.8283', '0.8516']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.37it/s]\n",
      "2022-07-05 20:21:55.668 | INFO     | src.training.train_model:trainloop:164 - Epoch 14 train 0.0301 test 0.4412 metric ['0.8047', '0.8570', '0.8429']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.65it/s]\n",
      "2022-07-05 20:21:57.413 | INFO     | src.training.train_model:trainloop:164 - Epoch 15 train 0.0229 test 0.4934 metric ['0.8440', '0.8579', '0.8806']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.30it/s]\n",
      "2022-07-05 20:21:59.276 | INFO     | src.training.train_model:trainloop:164 - Epoch 16 train 0.0236 test 0.4683 metric ['0.8113', '0.8547', '0.8382']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.23it/s]\n",
      "2022-07-05 20:22:01.184 | INFO     | src.training.train_model:trainloop:164 - Epoch 17 train 0.0115 test 0.4202 metric ['0.8251', '0.8864', '0.8531']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.35it/s]\n",
      "2022-07-05 20:22:02.826 | INFO     | src.training.train_model:trainloop:164 - Epoch 18 train 0.0173 test 0.5562 metric ['0.8104', '0.8263', '0.8552']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.98it/s]\n",
      "2022-07-05 20:22:04.547 | INFO     | src.training.train_model:trainloop:164 - Epoch 19 train 0.0290 test 0.4212 metric ['0.8560', '0.8588', '0.8985']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.28it/s]\n",
      "2022-07-05 20:22:06.177 | INFO     | src.training.train_model:trainloop:164 - Epoch 20 train 0.0184 test 0.5535 metric ['0.8289', '0.8624', '0.8778']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.87it/s]\n",
      "2022-07-05 20:22:08.017 | INFO     | src.training.train_model:trainloop:164 - Epoch 21 train 0.0146 test 0.3637 metric ['0.8938', '0.9015', '0.8996']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.05it/s]\n",
      "2022-07-05 20:22:09.670 | INFO     | src.training.train_model:trainloop:164 - Epoch 22 train 0.0253 test 0.5038 metric ['0.8322', '0.8896', '0.8574']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.94it/s]\n",
      "2022-07-05 20:22:11.415 | INFO     | src.training.train_model:trainloop:164 - Epoch 23 train 0.0186 test 0.5309 metric ['0.7834', '0.8167', '0.8361']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.62it/s]\n",
      "2022-07-05 20:22:13.213 | INFO     | src.training.train_model:trainloop:164 - Epoch 24 train 0.0173 test 0.5050 metric ['0.8099', '0.8399', '0.8490']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.33it/s]\n",
      "2022-07-05 20:22:15.052 | INFO     | src.training.train_model:trainloop:164 - Epoch 25 train 0.0061 test 0.4087 metric ['0.8261', '0.8637', '0.8569']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.03it/s]\n",
      "2022-07-05 20:22:16.686 | INFO     | src.training.train_model:trainloop:164 - Epoch 26 train 0.0180 test 0.5610 metric ['0.8208', '0.8395', '0.8634']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.04it/s]\n",
      "2022-07-05 20:22:18.394 | INFO     | src.training.train_model:trainloop:164 - Epoch 27 train 0.0069 test 0.5305 metric ['0.8430', '0.8444', '0.8983']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.42it/s]\n",
      "2022-07-05 20:22:20.088 | INFO     | src.training.train_model:trainloop:164 - Epoch 28 train 0.0042 test 0.4970 metric ['0.8323', '0.8534', '0.8924']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.53it/s]\n",
      "2022-07-05 20:22:21.836 | INFO     | src.training.train_model:trainloop:164 - Epoch 29 train 0.0133 test 0.5234 metric ['0.8408', '0.8607', '0.8831']\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.70it/s]\n",
      "2022-07-05 20:22:24.962 | INFO     | src.training.train_model:trainloop:164 - Epoch 30 train 0.0078 test 0.5159 metric ['0.8559', '0.8560', '0.8915']\n",
      "100%|██████████| 25/25 [00:02<00:00, 11.61it/s]\n",
      "2022-07-05 20:22:27.978 | INFO     | src.training.train_model:trainloop:164 - Epoch 31 train 0.0120 test 0.4262 metric ['0.8358', '0.8528', '0.8960']\n",
      "100%|██████████| 25/25 [00:02<00:00,  9.19it/s]\n",
      "2022-07-05 20:22:31.463 | INFO     | src.training.train_model:trainloop:164 - Epoch 32 train 0.0245 test 0.5197 metric ['0.8023', '0.8059', '0.8705']\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.43it/s]\n",
      "2022-07-05 20:22:33.575 | INFO     | src.training.train_model:trainloop:164 - Epoch 33 train 0.0176 test 0.3979 metric ['0.8769', '0.8853', '0.9216']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.56it/s]\n",
      "2022-07-05 20:22:35.650 | INFO     | src.training.train_model:trainloop:164 - Epoch 34 train 0.0192 test 0.5721 metric ['0.8336', '0.8538', '0.8472']\n",
      "100%|██████████| 25/25 [00:02<00:00, 12.24it/s]\n",
      "2022-07-05 20:22:38.138 | INFO     | src.training.train_model:trainloop:164 - Epoch 35 train 0.0100 test 0.5334 metric ['0.8459', '0.8608', '0.8681']\n",
      "100%|██████████| 25/25 [00:02<00:00,  8.58it/s]\n",
      "2022-07-05 20:22:41.661 | INFO     | src.training.train_model:trainloop:164 - Epoch 36 train 0.0242 test 0.4992 metric ['0.8259', '0.8382', '0.8607']\n",
      "100%|██████████| 25/25 [00:02<00:00, 10.80it/s]\n",
      "2022-07-05 20:22:44.921 | INFO     | src.training.train_model:trainloop:164 - Epoch 37 train 0.0061 test 0.3952 metric ['0.8703', '0.8920', '0.9058']\n",
      "100%|██████████| 25/25 [00:02<00:00, 11.81it/s]\n",
      "2022-07-05 20:22:47.564 | INFO     | src.training.train_model:trainloop:164 - Epoch 38 train 0.0038 test 0.4832 metric ['0.8153', '0.8460', '0.8798']\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.23it/s]\n",
      "2022-07-05 20:22:49.842 | INFO     | src.training.train_model:trainloop:164 - Epoch 39 train 0.0045 test 0.5426 metric ['0.8271', '0.8340', '0.8635']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.34it/s]\n",
      "2022-07-05 20:22:51.920 | INFO     | src.training.train_model:trainloop:164 - Epoch 40 train 0.0030 test 0.5891 metric ['0.8209', '0.8418', '0.8480']\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.76it/s]\n",
      "2022-07-05 20:22:54.139 | INFO     | src.training.train_model:trainloop:164 - Epoch 41 train 0.0125 test 0.5433 metric ['0.8583', '0.8625', '0.8782']\n",
      "100%|██████████| 25/25 [00:01<00:00, 13.89it/s]\n",
      "2022-07-05 20:22:56.486 | INFO     | src.training.train_model:trainloop:164 - Epoch 42 train 0.0015 test 0.4817 metric ['0.8329', '0.8537', '0.8819']\n",
      "100%|██████████| 25/25 [00:01<00:00, 15.58it/s]\n",
      "2022-07-05 20:22:58.534 | INFO     | src.training.train_model:trainloop:164 - Epoch 43 train 0.0008 test 0.5023 metric ['0.8508', '0.8571', '0.8953']\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.21it/s]\n",
      "2022-07-05 20:23:00.816 | INFO     | src.training.train_model:trainloop:164 - Epoch 44 train 0.0014 test 0.4902 metric ['0.8473', '0.8650', '0.8731']\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.83it/s]\n",
      "2022-07-05 20:23:03.123 | INFO     | src.training.train_model:trainloop:164 - Epoch 45 train 0.0070 test 0.5409 metric ['0.8225', '0.8544', '0.8616']\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.15it/s]\n",
      "2022-07-05 20:23:05.486 | INFO     | src.training.train_model:trainloop:164 - Epoch 46 train 0.0179 test 0.4454 metric ['0.8436', '0.8696', '0.8893']\n",
      "100%|██████████| 25/25 [00:01<00:00, 12.55it/s]\n",
      "2022-07-05 20:23:08.043 | INFO     | src.training.train_model:trainloop:164 - Epoch 47 train 0.0085 test 0.5089 metric ['0.8544', '0.8734', '0.8728']\n",
      "100%|██████████| 25/25 [00:02<00:00, 10.18it/s]\n",
      "2022-07-05 20:23:11.345 | INFO     | src.training.train_model:trainloop:164 - Epoch 48 train 0.0039 test 0.6046 metric ['0.8498', '0.8497', '0.8957']\n",
      "100%|██████████| 25/25 [00:01<00:00, 13.85it/s]\n",
      "2022-07-05 20:23:13.675 | INFO     | src.training.train_model:trainloop:164 - Epoch 49 train 0.0101 test 0.5039 metric ['0.8612', '0.8941', '0.8816']\n",
      "100%|██████████| 50/50 [01:47<00:00,  2.15s/it]\n"
     ]
    }
   ],
   "source": [
    "from src.training import train_model\n",
    "\n",
    "model = train_model.trainloop(\n",
    "    epochs=50,\n",
    "    model=model,\n",
    "    metrics=metrics,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    learning_rate=1e-3,\n",
    "    loss_fn=loss_fn,\n",
    "    train_dataloader=trainstreamer,\n",
    "    test_dataloader=teststreamer,\n",
    "    log_dir=log_dir,\n",
    "    train_steps=25,\n",
    "    eval_steps=25,\n",
    ")\n",
    "\n",
    "#log_dir=log_dir,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save an image from the training in tensorboard in the `figures` folder.\n",
    "Explain what you are seeing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your explanation here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Evaluate the basemodel\n",
    "Create a confusion matrix with the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 15.0, 'Predicted'), Text(33.0, 0.5, 'Target')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAEGCAYAAACjLLT8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAy4klEQVR4nO3dd3wUxfvA8c9zKVKD9DSagtIUkGKhSxcSRDEoyvdrRbGDqNgVRf1aEUX9oRSlSAch9A6hSEITCL2nUUNCJ7mb3x93pEBIguSaed6+9sXt7uzczLr3MMzOzooxBqWUUp7N4u4CKKWUypsGa6WU8gIarJVSygtosFZKKS+gwVoppbyAr7sLcDXnV4zWYSoOAW3fcncRPEaVgIruLoLHiDt9zN1F8Bjnzh2Q680j7djefMccv3I3Xff3XSuPDdZKKeVSNqu7S5ArDdZKKQVgbO4uQa40WCulFIBNg7VSSnk8oy1rpZTyAtZ0d5cgVxqslVIK9AajUkp5Be0GUUopL6A3GJVSyvPpDUallPIG2rJWSikvYE1zdwlypcFaKaVAbzAqpZRX0G4QpZTyAtqyVkopL6Ata6WU8nzGpjcYlVLK82nLWimlvID2WSullBfQiZyUUsoLaMtaKaW8gPZZK6WUF/Dwlw9Y3F0AV1q5ZQ/h7/xIl7eGMnz2yiv2Jx5P4akvRxPx0S90/2AYK/7eDcCsNZuJ+OiXjKX+M5+w/WASAGnpVgb+Pouwd36k67s/sXDdNpfW6Z9q374VWzYvIzY2itf7v3DFfn9/f8aO+ZHY2CiiVsykSpVQAMqUuZH58yZy4vgOBg/+JNsxDRrcxvp1C4mNjeKbbwa6pB4Fofm9dzNv9RQWrp1O75cfv2K/v78fg3/5jIVrpzN57m+EVAoCwM/Pl8+HfEDksgnMWPIHTe5pmHHM8AnfM2PJH8xeMZGBX76FxeIdP7V27VqyadNitmxZRv/+fa7Y7+/vz+jRP7BlyzKWL59O5cr26+Lee5uxcmUk0dHzWLkykpYt78k45sMPX2fXrtUcPRrrsnr8IzZb/hc38I4rqABYbTY+HTuHH199hGkfP8fctVvZk3A0W5pfZkXRoVFtJn7wDP97thufjp0DQOe7bmPiB88w8YNnGPRUV0LK3UjNyoEZx5QpWYyZg55n2sDnaHhLFZfX7VpZLBa+++4TwsJ7Ua9ea3r06EqtmjWypXniiYdJPplC7drNGDLkFz4d9DYA589f4MOPvuTNAR9fke8P33/Gc33eoHbtZlSvXo0OHVq7pD7Xw2Kx8OHnA3j64Zfp1LQ7Xbp1oPot1bKl6f7o/aSeTKVtk/sZ+fNYXn//ZQAienUDoEvLHjz+0PO8NbAvIgLAK08NILz1I9zXPIIy5UrTKbytayv2D1gsFgYP/piuXf9LgwZteeihcGpedl08/ngPkpNTqFu3Jd9/P5xBgwYAcPx4Mt27P0njxh145pl+jBjxbcYxs2cvpHnzri6tyz9hjDXfizsUmmC9ZV8ClSqUIbR8afx8fejYpA5LN+68It3p8xfsf567QPkbS16xf87aLXRsXCdjfXrURp68rykAFotQumQxJ9Wg4DRuXJ89e/azb99B0tLSmDjxT8LC2mdLExbWntGjJwEwZeosWrduBsDZs+dYtSqa847zdElgYAUCAkqwdu16AMaOmUx4eAcX1Ob63H5HHQ7sP8ShA/GkpaUza/p82nRqlS1N204tmTohEoC5Mxdxd/MmAFS/9SZWr4gG4MSxZFJTTnFb/doAnD59BgBfX1/8/PwwGBfV6J+7dF3s33+ItLQ0Jk2aSZcu7bKl6dKlHWPHTgFg6tTZtGplv/Y3bdpKYuIRAGJjd1KkSBH8/f0BWLt2A0lJR1xYk39IW9ae4UjyKQJLB2SsVyhdksPJp7Kl6RPegllrNtPu9e944bvxDHjkymAzLzqWjnfag3Xq2fMADJ2+jB4Df6X/T1M4nnLaibUoGCHBQcQdSsxYj49PIjgk6LI0gcTF2dNYrVZSUlMpW7b0VfMMDg4kLj4zz7j4RIKDAwu45AUvMKgCifGHM9aTEg5TMah8tjQVA8uT5EhjtVo5nXqa0mVuZPuWnbTp2BIfHx9CKwdTt14tgkIqZhw3YuIPrNm2gDOnzzJ3xiLXVOg6BGf5fw4QH59ISEhgDmkSAPu5SE09dcV10a3bfWzcuIWLFy86v9AFydjyv7iB04K1iNQUkTdFZIhjeVNEajnr+wrCnLVbCb+nHgu+fIWhrzzMO8P/xGbLbBH9vTeeIv5+1AipAIDVauNw8inq3xzKhPef5vabQ/h60kJ3FV+52ORxM0hKOMy0haN555PXWB+9Cas184f8ZMSL3FO3A/43+HF388ZuLKnr1KpVg08+GcCLL77l7qJcu8LYshaRN4HxgABrHYsAf4jIgFyO6y0iMSISM3zGkgItU4XSJUlKTs1YP5J8ioqls3dzTIvaSIfG9r9P6t0cyoW0dJJPn83YP2/tVjo1yewCubFEUYr4+9HmjpoAtG9Ui22OG4+eLD4hkdBKmS3pkJBAErK0iu1pkggNtafx8fGhVEAAx48nXzXPhIQkQrO0zkNDgkhI8PxzkZR4JFtrODC4IocTs9/LOJx0lEBHGh8fH0oElCD5xEmsViufvvcN4a170uc/rxEQUJL9ew5kO/bihYssnLOMNp1aOr8y1ykhy/9zgJCQIOLjk3JIEwzYz0VAQMmM6yIkJJAJE4bx9NP92LfvoOsKXlCs6flf3MBZLeungMbGmM+NMWMcy+dAE8e+HBljhhljGhljGj0VXrA3p+pUDebg4RPEHU0mLd3K3LVbaVnvlmxpgsqU4q9t+wHYm3CMi2nplHH0Qdtshnkx2+iYJViLCC3r1SB6h/2Yv7bt5+bL/gntiWJiNlG9ejWqVq2En58fERFdiYxckC1NZOQCevV6CIAHH+jM0qVXjp7JKinpCKmpp2nS5A4AHn2sOzNnzndOBQrQ5g2xVK1WidDKwfj5+dL5/vYsmrssW5pFc5fxQI8uAHQMa8OaKHs/dZGiRSharAgATVveidVqZffOfRQrXpTyFcsB9oDWql0z9u7a77pK/UOXrosqVezXxUMPhTFrVvbrYtashTz66IMAPPDAfSxbtgqAUqUCmDp1JO+99z9Wr45xedkLhId3gzhrnLUNCAYOXLY9yLHP5Xx9LLzVsyN9Bv+BzWbj/qb1qR5SnqHTl1KnajCt6t/CaxFtGfjbLMYs+AsRYeCTYRl399ftPEBgmQBCy2fvn3u1+7288+uffDl+AaVLFmPgE2HuqN41sVqtvPrqe8yKHIvFx8JvoyYQu20nH7zfn3XrNxEZuYCRI8czauR3xMZGkXziJI/1ej7j+J07VhMQUBJ/fz/CwzrQuXNPtm3fxUsvv83wX7+hSNEizJu3lLlzF7uxlvljtVr56K0vGDHxB3wsPkz+409279jLK28+x+aNsSyet5xJY//kqx8/ZuHa6ZxMTqFvb/vImLLlSjNi4g8YmyEp8Qj9n38PgKLFivLz6G/w9/fHYhHWrIzhj1FT3FnNfLFarfTt+z4zZ/6Oj48Pv/02kW3bdvHee/1Yv/5vZs1ayKhRExgx4lu2bFlGcvJJevV6EYDnnvsvN99clbfeepm33rKPlgkL68XRo8cZNOgtevToSrFiRdm9ew0jR45n0KDBbqzpVXj4QzFiTMHfpRaRjsAPwC7gkGNzZaA68KIxZm5eeZxfMdrzb5+7SEBbL+z/c5IqARXzTlRIxJ0+5u4ieIxz5w7Idecxa3C+Y07Rzq9e9/ddK6e0rI0xc0XkFuzdHiGOzfFAtHHXIEWllMpNYZ0bxBhjA9Y4K3+llCpQHv64uc4NopRS4PF91hqslVIKCm83iFJKeRUPb1kXmsfNlVIqVwX4BKOIdBSRHSKyO6cHAUWksogsEZENIvK3iNyXV54arJVSCsCY/C+5EBEfYCjQCagNPCIitS9L9i4w0RjTAHgY+DGv4mk3iFJKAaQX2GiQJsBuY8xeABEZD3QFsk7obYBLM8uVAhLyylSDtVJKwTXdYBSR3kDvLJuGGWOGOT6HkPkwIEAccOdlWXwIzBeRl4DiQJ4TnmuwVkopuKYbjI7APCzPhFf3CDDKGPO1iNwNjBaRuo7nU3KkwVoppSDPvuhrEA9UyrIe6tiW1VNAR/vXmtUiUgQoB1z1LQ16g1EppaAgR4NEAzVEpJqI+GO/gTjjsjQHgTYAjnn+iwBHyYW2rJVSCgpsnLUxJl1EXgTmAT7ACGPMVhEZCMQYY2YArwG/iEhf7DcbHzd5zKqnwVoppQBjLbg55owxs4HZl217P8vnWKDpteSpwVoppcDjn2DUYK2UUqBzgyillFewefb7TjRYK6UUaDeIUkp5hQK8wegMGqyVUgq0Za2UUl5B+6yVUsoL6GgQpZTyAtqy/mcC2r7l7iJ4jDPxy91dBI9RPKSFu4vgMWwFN/GQAoz2WSullBfQ0SBKKeUFtBtEKaW8gHaDKKWUF9CWtVJKeQEduqeUUl5AW9ZKKeX5TLqOBlFKKc+nLWullPIC2metlFJeQFvWSinl+YwGa6WU8gJ6g1EppbyAtqyVUsoLaLBWSinPZzx8ylkN1kopBdqyVkopr6DBWimlPJ9J14dilFLK83l2rNZgrZRSoA/FKKWUd9BgrZRSXsDDu0Es7i6AK7Vv34otm5cRGxvF6/1fuGK/v78/Y8f8SGxsFFErZlKlSigAZcrcyPx5EzlxfAeDB3+S7ZgGDW5j/bqFxMZG8c03A11Sj4IQtSaGLg8/TaeIJ/l19MQr9ickHeaplwfQ7T99ePzFN0g6cjRj39dDh9P10WcJ69mbT7/9KWN86tbtu+jWqw+dIp7Mtt3T6XWRqUP7VmzdspztsVG88XrO52Lc2J/YHhvFqqjMcwHw5hsvsj02iq1bltO+Xct85+kpjM3ke3GHQhOsLRYL3333CWHhvahXrzU9enSlVs0a2dI88cTDJJ9MoXbtZgwZ8gufDnobgPPnL/DhR1/y5oCPr8j3h+8/47k+b1C7djOqV69Ghw6tXVKf62G1Wvnk66H89PXHzBj7f8xeuJQ9+w5kS/PVD78S3rEN037/iT5P9GTwz6MA2LA5lg2bY5n6+49MH/0TW7ftJHrDZgA+/uoHPnzzZWZPGM7BuASi1sS4umrXTK+LTBaLhSHfDaJL2GPcVq81PXrcT61a2c/Fk088QnJyCjVrN2PwkF/47NN3AKhVqwYREV25vf69dO7yKN8P+RSLxZKvPD2FSTf5Xtyh0ATrxo3rs2fPfvbtO0haWhoTJ/5JWFj7bGnCwtozevQkAKZMnUXr1s0AOHv2HKtWRXP+/IVs6QMDKxAQUIK1a9cDMHbMZMLDO7igNtdn87adVA4NplJIEH5+fnRq05LFK9ZkS7Nn30GaNKwPQJM76rFkxWoARISLFy+Slp7OxbQ00tKtlC1zI0ePneDMmbPUq1sLESG8YxsWO47xZHpdZGrSuMEV5yI8LHu5w7OeiymzuNdxLsLDOjBx4p9cvHiR/fsPsWfPfpo0bpCvPD2G7RoWNyg0wTokOIi4Q4kZ6/HxSQSHBF2WJpC4OHsaq9VKSmoqZcuWvmqewcGBxMVn5hkXn0hwcGABl7zgHTl6jMAK5TPWK1Yox5Gjx7OlubXGTSxcthKAhctWcebsOU6mpFK/bi0a33E7rcMfpXX4ozS98w5urlqZw0ePUbFCucw8y5fj8GV5eiK9LjIFhwRyKC4hYz2ncmdNY7VaSUmxn4vg4ByODQnMV56ewtjyv7iDy4O1iDyRy77eIhIjIjE26xlXFktdpv8LTxOzYTPdH3+BmI2bqVi+LBaLhYNxCezdf4hF00azePoY1q7bxLqNW9xdXKWuXwG2rEWko4jsEJHdIjLgKmkiRCRWRLaKyLi88nTHaJCPgJE57TDGDAOGAfjfEFqgHUPxCYmEVspsMYWEBJKQpfVjT5NEaGgQ8fGJ+Pj4UCoggOPHk6+aZ0JCEqFZWmGhIUEkJCQVZLGdokL5ctluGB4+cowK5ctelqYs3332HmD/5/7CpVEElCzB5BlzqVenJsWKFQWg2V2N2LR1G2Ed2nD4yLHMPI8eo+JleXoivS4yJcQnUSk0OGM9p3JfSpNxLkrZz0VCQg7HxtuPzStPT1FQLWYR8QGGAu2AOCBaRGYYY2KzpKkBvAU0NcYki0iFvPJ1SstaRP6+yrIZqOiM78xLTMwmqlevRtWqlfDz8yMioiuRkQuypYmMXECvXg8B8OADnVm6dGWueSYlHSE19TRNmtwBwKOPdWfmzPnOqUABqlvzFg7GJRCXkERaWhpzFi2jdbO7sqVJPpmCzWa/en8ZPYFune39uEEVyxOzcTPp6VbS0tOJ2biZm6pUony5MhQvXoxNW7ZhjGHG3EVX5OmJ9LrIFB2z8YpzMTMye7lnRs7PPBcPdmaJ41zMjJxPRERX/P39qVq1EtWrV2Nt9IZ85ekpTHr+lzw0AXYbY/YaYy4C44Gul6V5BhhqjEkGMMYcyStTZ7WsKwIdgMubHwKsctJ35spqtfLqq+8xK3IsFh8Lv42aQOy2nXzwfn/Wrd9EZOQCRo4cz6iR3xEbG0XyiZM81uv5jON37lhNQEBJ/P39CA/rQOfOPdm2fRcvvfw2w3/9hiJFizBv3lLmzl3sjupdE19fH97u24dn+72L1WqlW5f2VL+pCj/88jt1at5C6+Z3Eb3hbwb/PAoRoWG9urz7mv1ctG/djLXrN9HtP30QgWZ3NqKVIyi/+9oLvDvoG85fuEDzuxrT/O7G7qxmvuh1kclqtfLKq+8ye9Y4fCwWRv02gdjYnXz4QX9i1tnPxYiR4/lt1BC2x0aRnHySno/Zz0Vs7E4mT57J5k1LSLdaefmVdzL+ss8pT090LS1rEekN9M6yaZijZwAgBDiUZV8ccOdlWdziyGcl4AN8aIyZm+t3OmMsrIgMB0YaY6Jy2DfOGNMzrzwKuhvEm52JX+7uIniM4iEt3F0Ej2HzknHsrpB+MV6uN4/DrVvm+4RWXLLsqt8nIt2BjsaYpx3rvYA7jTEvZkkTCaQBEUAosBy4zRhz8mr5OqVlbYx5Kpd9eQZqpZRyOXPd8f6SeKBSlvVQx7as4oC/jDFpwD4R2QnUAKKvlmmhGbqnlFK5KcChe9FADRGpJiL+wMPAjMvSTAdaAYhIOezdIntzy1TnBlFKKcDYCqZlbYxJF5EXgXnY+6NHGGO2ishAIMYYM8Oxr72IxAJW4HVjTK4PJmiwVkopwGYtsG4QjDGzgdmXbXs/y2cD9HMs+aLBWimlcN+TifmlwVoppSi4bhBn0WCtlFKAp4+E1GCtlFJ4fss6z6F7IvK//GxTSilvZrNKvhd3yM8463Y5bOtU0AVRSil3MjbJ9+IOV+0GEZE+wPPATSLyd5ZdJYHcZ7JRSikvYwruCUanyK3PehwwB/gMyDof6yljzAmnlkoppVzM04fuXbUbxBiTYozZb4x5BPtz7vcaYw4AFhGp5rISKqWUC9iM5HtxhzxHg4jIB0Aj4FbsLw3wB8YATZ1bNKWUch1v7ga5pBvQAFgPYIxJEJGSTi2VUkq5mLtGeeRXfoL1RWOMEREDICLFnVwmpZRyOU8fZ52fYD1RRP4PuFFEngGeBH5xbrGUUsq13NUXnV95BmtjzFci0g5Ixd5v/b4xZkEehymllFf5N/RZ4wjOGqCVUv9aXj83iIicAi6vRgoQA7xmjMn17QZKKeUNvL4bBBiM/X1h47C/nfxh4Gbso0NG4Hg1jVJKeTPbv+AGY7gxpl6W9WEistEY86aIvO2sgimllCv9G1rWZ0UkApjsWO8OnHd8dlovTwn/os7K2uuUDG3l7iJ4jNTVP7q7CB6jYou+7i7Cv4qn32DMz6x7jwK9gCPAYcfnx0SkKPCiE8umlFIu49WPm4uID/C8MSbsKkmiCr5ISinleh4+GCT3YG2MsYpIM1cVRiml3MVqy09Hg/vkp896g4jMACYBZy5tNMZMdVqplFLKxTx8htR8BesiwHHg3izbDKDBWin1r2Hw7BuM+Xnc/AlXFEQppdzJ5uGd1vl5grEI8BRQB3srGwBjzJNOLJdSSrmUzcNb1vnpUR8NBAIdgGVAKHDKmYVSSilXM0i+F3e4arAWkUut7urGmPeAM8aY34DOwJ2uKJxSSrmKFcn34g65tazXOv5Mc/x5UkTqAqWACk4tlVJKuZjtGhZ3yM9okGEiUhp4F5gBlADec2qplFLKxbx56F4FEenn+HxpRMhQx5/6ai+l1L+KNw/d88Heis6pBh4+yEUppa6Nh8+QmmuwTjTGDHRZSZRSyo08fehebsHas0uulFIFyOruAuQht2DdxmWlUEopN7OJZ7dPrzp0zxhzwpUFUUopdzLXsORFRDqKyA4R2S0iA3JJ96CIGBFplFeenj0noFJKuUhBjbN2vAdgKNAJqA08IiK1c0hXEngF+Cs/5dNgrZRS2EeD5HfJQxNgtzFmrzHmIjAe6JpDuo+B/5H5msRcabBWSimu7XFzEektIjFZlt5ZsgoBDmVZj3NsyyAidwCVjDGz8lu+/DzBqJRS/3rXMs7aGDMMGPZPvkdELMA3wOPXcpwGa6WUokAfN48HKmVZD3Vsu6QkUBdYKvYRKIHADBEJN8bEXC3TQtUN0qZtc/5aP4+YjQt5pV/vK/b7+/szfNRgYjYuZMHiyVSqnO1fLoSEBnEwcSMvvvxUxraNW5YQtSaSZStnsGiZ97w8p127lvz99xK2bl1O//7PX7Hf39+f0aOHsnXrcpYv/5MqVUIBKFPmRubNG8+xY9v49tvsz0xFRIQTEzOf6Oh5zJjxO2XLlnZJXa7Xyo3bCe/3BV1e/Zzhfy6+Yn/C0WSe+eT/6P7G1zw18CcOHz+ZsW/GshjC+v6PsL7/Y8ayzN9Z7N44Hnzja7q8+jmfj5qOMd7x0G+bti2IWb+ADZsW07ffs1fs9/f3Z+RvQ9iwaTGLlkyhsuM3ckfD21mxaiYrVs0kanUkXcLaZxxTqlRJfh/zA9Hr57N23TwaN2ngsvpciwIcDRIN1BCRaiLiDzyMfV4l+/cYk2KMKWeMqWqMqQqsAXIN1FCIgrXFYuGLrz8k4oGnubtxJx7s3oVbb62eLc1j/+nOyZOpNKrflp+GjuTDga9n2z/os7dZtGD5FXmHd+5Fy6bhtGn5gFPrUFAsFgvfffcJXbv+l/r12xAREU7NmjWypXn88R6cPJlCnTot+P77X/nkk7cAOH/+Ah999DUDBgzKlt7Hx4evvvqQDh160LhxBzZv3k6fPo+7qkr/mNVm49OR0/jxzaeY9lV/5q7ayJ64w9nSfDM2krDmDZn8xWv0fqAd342fA0DK6bP8PHUBYz5+ibEfv8TPUxeQevosAJ+MmMoHz3Rn5rdvcjDpGCs37XB53a6VxWLh628+pPsDT9KkUQcefCiMW2tm/438578PcfJkCg3q3cuPQ0fy0cdvArAtdietmt9P83vCePD+Jxg85BN8fHwA+PyL91m4YDmN72hP07u6sHPHbpfXLT8K6gajMSYdeBGYB2wDJhpjtorIQBEJ/6flKzTBumGj29m39wAH9h8iLS2NqVNm0alL9ud+7uvclvHj7K3jP6fPpUWruzP3dWnLgQNxbN+2y6XldobGjeuzZ89+9u07SFpaGpMmzSQsS0sIICysPWPGTAZg6tTZtG7dFICzZ8+xalU0Fy5kv4EtIogIxYsXAyAgoASJidmDnifasvsglQLLEVqxLH6+vnS8uz5LY7ZmS7Mn7jBN6tqDVpM6N7N0nX3/qk07uOu2GpQqUYyAEsW467YarNy0g6PJqZw5d57ba1RBRAhr3pDFMVtcXrdr1bBRPfbuPcD+S7+RyZF07tw2W5r7Ordl3Fj7b2T6tDm0dPxGzp07j9VqfwawSJEbMv4lERBQgqZNG/P7bxMBSEtLIyXFM99dUpBTpBpjZhtjbjHG3GyMGeTY9r4xZkYOaVvl1aoGJwZrEakpIm1EpMRl2zs66ztzExQUSHx8YsZ6QnwSQUEVs6cJrkh8XBIAVquV1JTTlClbmuLFi/FK39588dn3V+RrjGHK9JEsXj6N/z7Rw7mVKCDBwYHExSVkrMfHJxIcXPGqaaxWK6mpp3Lt1khPT+fll98hJmY++/bFUKtWDUaOHO+cChSgI8mpBJa9MWO9QtlSHE5OyZbm1ipBLFq7GYBF0Vs4c+4CJ0+d4UhyCoFlMo+tWKYUR5JTOHIihYplSmVuL1uKIydSnVqPghAcXJH4uMzfSHx8EkHBl/9GAjPS2H8jpyjjuC4aNqrHmug5rPprNn1feQ+r1UqVKpU4duwEP/78BStWzuD7Hz6lWLGirqvUNbBK/hd3cEqwFpGXgT+Bl4AtIpJ1jOGnuRyXMRzmQlrK1ZK53Jtvv8RPP4zkzJmzV+y7r/0jtG5+PxEPPMVTzzzK3U0bu6GE7ufr60vv3r246677qFatEZs3b+ONN15wd7EKRL9HuxCzbS8RA75l3ba9VChTCoul0PyjNN/WxWzirsadaN2yG/1ee44bbvDH19eXevXrMPzXsTRvGs6Zs+fo+9pz7i5qjv4NLx/4J54BGhpjTotIVWCyiFQ1xnxHLhNEZR0OU6ZkjQK9I5OYmERISFDGenBI4BX/TE9MOExIaCAJCUn4+PgQUKoEJ44n07BRPcK7duTDj9+gVKkAbDYb589f4NdhYzLyOHbsBLNmLqBhw9tZvTK6IIte4BISkggNDc5YDwkJIiHhcI5p4uMd5yKgJMePJ181z3r17A9o7d17AIApUyJzvHHpaSqUDiApyw3DI8dTqFi6VPY0ZUrxbb//AnD2/AUWrt1MQPGiVChdiuhtezLSHT6RQuNaN1OhTCkOn8hsbBw+nkKFMgHOrUgBSEg4TEho5m8kJCSQxITLfyNJhIQGZfmNlOTEZdfFzh17OHPmLLVr30p8fCLx8Umsi9kEwJ/T59C3n+cGa0/mrOaBxRhzGsAYsx9oBXQSkW9w02x+69dt5qabq1K5Sih+fn488GBn5s5alC3NnNmLeLin/SZh1/s7smLZGgA6d+hJ/bqtqV+3NT//OIpvv/6ZX4eNoVixopQoYX8PQ7FiRWndphnbYne6tmL/QEzMJqpXr0bVqpXw8/PjoYfCiIxckC1NZOQCHnusOwAPPHAfS5euyjXPhITD1KxZg3LlygDQpk1ztm/3zBtJWdW5uRIHk44Rd+QEaenpzF29kZYNsz8ZnJx6BpvN/lMe/udi7m9l/9fTPfVuZfXfO0k9fZbU02dZ/fdO7ql3K+VLB1C8aBH+3nUAYwwzV6yjdcM6Lq/btVq/7m9uvrkqVS79Rrp3Yfbs7L+R2bMX0fNR+2/k/m6dWL5sNQBVqoRm3FCsVCmYGrfcxIGDcRw5coz4+ESq16gGQMtW97DDQ6+LgpwbxBmc1bI+LCL1jTEbARwt7C7ACOA2J31nrqxWK2/0/4jJ00fgY/Fh7OjJbN++m7feeYUNGzYzd/Zixvw+iZ9/+YqYjQtJTj7J00/0zTXP8hXKMXqc/eU5vr6+TJ44k0ULV7iiOtfFarXy6qvvMXPmaHx8fPjttwls27aT99/vx7p1m5k1awGjRk1gxIjBbN26nBMnTvKf/7yYcfyOHSspWbIk/v5+hIV1oEuXx9i+fReDBg1m4cJJpKWlc/BgPM880y+XUngGXx8f3nr8fvp89gs2m437WzWheqVAhk6aR51qobRqVIeYbXsY4hgB0rDWTbz9RDcASpUoRu9uben57hAAnn2gHaVK2G+wvvNEN977eQIXLqbRtH5NmtWv6Z4KXgOr1Ur/1z5i6vRR+PhYGDN6Mtu37eLtd19lw/rNzJm9iNG/TWTYr1+zYdNikpNP8uTjrwBw192N6Pvas6SlpWNsNl7r+0FGi/uN1z7i1+Hf4ufvx/59h3ihzxvurOZVefrLB8QZ4z9FJBRIN8Yk5bCvqTFmZV55FHQ3iDc7m3bB3UXwGCdX/eDuIniMii1yb0wUJimn91x3qP228mP5jjl9D45xeWh3SsvaGBOXy748A7VSSrmaN798QCmlCg1P7wbRYK2UUnj+aBAN1kophftGeeSXBmullAJsHh6uNVgrpRR6g1EppbyC9lkrpZQX0NEgSinlBbTPWimlvIBnh2oN1kopBWiftVJKeQWrh7etNVgrpRTaslZKKa+gNxiVUsoLeHao1mCtlFKAdoMopZRX0BuMSinlBbTPWimlvIBnh2oN1kopBWjLWimlvILeYFRKKS9gtGX9z5TyL+buIniM1Atn3V0Ej1Gr3XvuLoLHSBrXx91F+FfR0SBKKeUFtBtEKaW8gM1oy1oppTyeZ4dqDdZKKQXo0D2llPIKOhpEKaW8QLqHB2uLuwuglFKewFzDf3kRkY4iskNEdovIgBz29xORWBH5W0QWiUiVvPLUYK2UUtiH7uV3yY2I+ABDgU5AbeAREal9WbINQCNjzO3AZOCLvMqnwVoppQBjTL6XPDQBdhtj9hpjLgLjga6XfdcSY8ylp93WAKF5ZarBWimlsI8Gye8iIr1FJCbL0jtLViHAoSzrcY5tV/MUMCev8ukNRqWU4toeNzfGDAOGXe93ishjQCOgZV5pNVgrpRQFOs46HqiUZT3UsS0bEWkLvAO0NMZcyCtTDdZKKQX56YvOr2ighohUwx6kHwZ6Zk0gIg2A/wM6GmOO5CdTDdZKKUXBTeRkjEkXkReBeYAPMMIYs1VEBgIxxpgZwJdACWCSiAAcNMaE55avBmullKJgn2A0xswGZl+27f0sn9tea54arJVSCp0bRCmlvILVePaM1hqslVIKnchJKaW8gr58QCmlvIBnh2oN1kopBegNRqWU8gqeHqwL1UROLe69h0V//cmS6Jk898qTV+z39/fj+1+/YEn0TKbNH0NIpWAAfH19+Wrox8xZMZkFq6fR51X7sf43+DN9wVhmL5vIvJVTefXNPi6tz/Xo0L4VW7csZ3tsFG+8/sIV+/39/Rk39ie2x0axKmomVapkTgr25hsvsj02iq1bltO+Xct85+mp9LrItHL7Ibp+MZGwzycwYvHGK/YnJp/m6Z8j6fHtVB76egorth0EYPPBI0R8MyVjWbx5HwAX0tJ5dMh0Ir6ZwgNfTeLHeetcWZ1rYjW2fC/uUGha1haLhYFfvE2vB58lKeEwfy4cx8K5S9m9Y29GmojHupFyMpXWjcPo0q0jAz54lZeefoP7urbD39+fTs27U6RoERasmsqMKXOJP5RAz/uf5uyZc/j6+jJp9iiWLopiY8xmN9Y0bxaLhSHfDaLjfY8QF5fImtWzmRk5n23bdmWkefKJR0hOTqFm7WZERITz2afv0PPRPtSqVYOIiK7cXv9egoMrMm/OeGrVaQ6QZ56eSK+LTFabjc+mreTn3vdRsVRxHh0ynZZ1qnBzxdIZaX5ZtIH2t99ExD212XM4mReHz2VOrcpUDyzDuFe64etj4WjqWSK+mUKL2lXw9/Xhl2c7U+wGP9KsNp4YOoNmNUO5vUpFN9Y0Z54+GqTQtKzr3VGXA/sOcehAPGlp6cycNpd2nVplS9OuU2umjJ8BwJwZC7inRRPAPmdAsWJF8fHxoUiRG0i7mM7pU6cBOHvmHAC+fr74+vp6/l0KoEnjBuzZs599+w6SlpbGxIl/Eh7WIVua8LD2jB49CYApU2Zxb+tmju0dmDjxTy5evMj+/YfYs2c/TRo3yFeenkivi0xbDh6lUrkAQssG4OfrQ4f6N7N064FsaQQ4c+EiAKfPXaR8QDEAivr74utjDycX09NxPEKNiFDsBj8A0q020m22jH2epgDns3aKQtOyDgyqQGJ8UsZ6UsIR6je8LVuaikEVSEywp7FarZxKPU3pMjcyZ8ZC2nVqzV+xCylatCifvPslKSdTAXvLbObiP6hSrTKjR0xg4zrPbj0BBIcEciguIWM9Lj6RJo0bXDWN1WolJSWVsmVLExwcyF9r12c7NjgkECDPPD2RXheZjqSeIfDGEhnrFUsVZ/PB7HMMPde+IX1+mc0fK2M5dzGN/+t9X8a+zQeP8MHEZSQmn2bQw60ygrfVZuORwdM4dDyVHvfU5rbKFVxToWtUaPusRaSJiDR2fK7teOfYfXkd54nq3VEXq9XKXXXa0eKO+3j6hf9QqYp9LnGbzUbnVj24+7b21GtQl1tqVndzaZWrFMbrYu6G3YQ3uoX57/bkhyc78u4fS7HZ7EHutsoVmNr/Ica+fD/Dl2ziQlo6AD4WCxP7Pci8d3uy5dBRdiedcGcVrsrTW9ZOCdYi8gEwBPhJRD4DfgCKAwNE5J1cjst4+8Kp88cLtExJiUcIcrQAAQKDK5CUeDhbmsOJRwgKtqfx8fGhZEAJkk+cpGv3TixfvIr09HSOHztBzF8bub1+nWzHnko9xeqoaFq2uadAy+0MCfFJVAoNzlgPDQkiISHpqml8fHwoVSqA48eTSUjI4dj4pHzl6Yn0ushUIaA4SSdPZ6wfTjlDhVLFs6WZFr2D9vVuAqBe1YpcSLdy8uz5bGluqliaYv6+7E5KzrY9oOgNNL45mJXb45xUg+tjxZbvxR2c1bLuDjQFWgAvAPcbYz4GOgA9rnaQMWaYMaaRMaZRySJlC7RAf2/YStWbKhNaOQQ/P1/CunVk4Zxl2dIsnLuUBx+2z1LYKbwdq1esBSA+Lom7m9v7KYsWK0qDRrexZ9c+ypQtTcmAkgDcUOQGmre6iz279hdouZ0hOmYj1atXo2rVSvj5+RER0ZWZkfOzpZkZOZ9evR4C4MEHO7Nk6cqM7RERXfH396dq1UpUr16NtdEb8pWnJ9LrIlOdSuU5eCyV+BOppKVbmbdxDy1rV86WJujGEvy1y97dtfdwMhfTrZQuXoT4E6mkW+1BLCH5FPuPphBcpiQnTp8j9Zx9Xv3zaems2RVHtQqlXFuxfLIZk+/FHZzVZ51ujLECZ0VkjzEmFcAYc05E3PLXktVq5YM3P+P3ST9h8bEwadx0du3YQ98Bz7N541YWzl3GhDHT+PanQSyJnknKyVReevoNAEYPH8+X3w9k3sqpiMDkcX+yPXYXNWvX4Kuhn+DjY0EsFmZNn8/i+cvdUb1rYrVaeeXVd5k9axw+FgujfptAbOxOPvygPzHrNhEZuYARI8fz26ghbI+NIjn5JD0fex6A2NidTJ48k82blpButfLyK+9gs9n/l+aUp6fT6yKTr4+FAfffQ59f5mCzGbo2uZXqgWX4cV4MtUPL06pOFfqF3cXASSsYu8LeB/9RREtEhA37DjNiyTx8LRYsFuGtbk0pXbwIOxOO896EZdhs9iDXvt5NtKhdxc01zZmnjwYRZ/S/iMhfQGtjzFkRsRhjH5goIqWAJcaYO/LKo1rZep595lzo0Klj7i6Cx6hUspy7i+AxYkf2cncRPEbR8P7XPcSkVoUm+Y45246sdfmQFme1rFtceqfYpUDt4Af810nfqZRS/5int6ydEqyv9vJHY8wxQJuJSimPo7PuKaWUF9CXDyillBcolN0gSinlbYy2rJVSyvN5+uPmGqyVUgrc9hh5fmmwVkoptGWtlFJewWrTPmullPJ4OhpEKaW8gPZZK6WUF9A+a6WU8gLaslZKKS+gNxiVUsoLaDeIUkp5Ae0GUUopL6BTpCqllBfQcdZKKeUFtGWtlFJewObhU6Ra3F0ApZTyBMaYfC95EZGOIrJDRHaLyIAc9t8gIhMc+/8Skap55anBWimlKLhgLSI+wFCgE1AbeEREal+W7Ckg2RhTHfgW+F9e5dNgrZRSgLmGJQ9NgN3GmL3GmIvAeKDrZWm6Ar85Pk8G2oiI5Japx/ZZ7zu+KdeCu4qI9DbGDHN3OTyBnotMei4y/VvORfrF+HzHHBHpDfTOsmlYlnMQAhzKsi8OuPOyLDLSGGPSRSQFKAscu9p3ass6b73zTlJo6LnIpOciU6E7F8aYYcaYRlkWp/9lpcFaKaUKVjxQKct6qGNbjmlExBcoBRzPLVMN1kopVbCigRoiUk1E/IGHgRmXpZkB/NfxuTuw2ORx59Jj+6w9iNf3xRUgPReZ9Fxk0nORhaMP+kVgHuADjDDGbBWRgUCMMWYGMBwYLSK7gRPYA3quxNMnL1FKKaXdIEop5RU0WCullBfQYH0VeT0uWpiIyAgROSIiW9xdFncSkUoiskREYkVkq4i84u4yuYuIFBGRtSKyyXEuPnJ3mf7ttM86B47HRXcC7bAPaI8GHjHGxLq1YG4iIi2A08Dvxpi67i6Pu4hIEBBkjFkvIiWBdcD9hfG6cDxtV9wYc1pE/IAo4BVjzBo3F+1fS1vWOcvP46KFhjFmOfY71oWaMSbRGLPe8fkUsA37k2iFjrE77Vj1cyza8nMiDdY5y+lx0UL5o1Q5c8yS1gD4y81FcRsR8RGRjcARYIExptCeC1fQYK3UNRKREsAU4FVjTKq7y+MuxhirMaY+9if0mohIoe0icwUN1jnLz+OiqhBy9M9OAcYaY6a6uzyewBhzElgCdHRzUf7VNFjnLD+Pi6pCxnFTbTiwzRjzjbvL404iUl5EbnR8Lor9Zvx2txbqX06DdQ6MMenApcdFtwETjTFb3Vsq9xGRP4DVwK0iEiciT7m7TG7SFOgF3CsiGx3Lfe4ulJsEAUtE5G/sjZsFxphIN5fpX02H7imllBfQlrVSSnkBDdZKKeUFNFgrpZQX0GCtlFJeQIO1Ukp5AQ3WyilExOoY2rZFRCaJSLHryGuUiHR3fP5VRGrnkraViNzzD75jv4iU+6dlVMrZNFgrZzlnjKnvmKXvIvBc1p2Ol4ReM2PM03nMctcKuOZgrZSn02CtXGEFUN3R6l0hIjOAWMdEQF+KSLSI/C0iz4L9SUER+cExn/hCoMKljERkqYg0cnzuKCLrHXMqL3JMrvQc0NfRqm/ueNJuiuM7okWkqePYsiIy3zEX86+AuPicKHVN9IW5yqkcLehOwFzHpjuAusaYfSLSG0gxxjQWkRuAlSIyH/tsdrcCtYGKQCww4rJ8ywO/AC0ceZUxxpwQkZ+B08aYrxzpxgHfGmOiRKQy9qdSawEfAFHGmIEi0hkorE9lKi+hwVo5S1HH9Jlgb1kPx949sdYYs8+xvT1w+6X+aKAUUANoAfxhjLECCSKyOIf87wKWX8rLGHO1+bbbArXt03oAEOCYNa8F8IDj2FkikvzPqqmUa2iwVs5yzjF9ZgZHwDyTdRPwkjFm3mXpCnK+DQtwlzHmfA5lUcpraJ+1cqd5QB/HtKOIyC0iUhxYDvRw9GkHAa1zOHYN0EJEqjmOLePYfgoomSXdfOClSysiUt/xcTnQ07GtE1C6oCqllDNosFbu9Cv2/uj1jpfx/h/2f+1NA3Y59v2Ofca/bIwxR4HewFQR2QRMcOyaCXS7dIMReBlo5LiBGUvmqJSPsAf7rdi7Qw46qY5KFQiddU8ppbyAtqyVUsoLaLBWSikvoMFaKaW8gAZrpZTyAhqslVLKC2iwVkopL6DBWimlvMD/A50OenzD8QnOAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for _ in range(10):\n",
    "    X, y = next(teststreamer)\n",
    "    yhat = model(X)\n",
    "    yhat = yhat.argmax(dim=1)\n",
    "    y_pred.append(yhat.tolist())\n",
    "    y_true.append(y.tolist())\n",
    "\n",
    "yhat = [x for y in y_pred for x in y]\n",
    "y = [x for y in y_true for x in y]\n",
    "\n",
    "cfm = confusion_matrix(y, yhat)\n",
    "cfm_norm = cfm / np.sum(cfm, axis=1, keepdims=True)\n",
    "plot = sns.heatmap(cfm_norm, annot=cfm_norm, fmt=\".3f\")\n",
    "plot.set(xlabel=\"Predicted\", ylabel=\"Target\")\n",
    "\n",
    "#confusion matrix opgeslagen in map 'figures'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save this in the figures folder.\n",
    "Interpret this. \n",
    "\n",
    "- What is going on?\n",
    "- What is a good metric here?\n",
    "- how is your answer to Q1 relevant here?\n",
    "- Is there something you could do to fix/improve things, after you see these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Antwoord Agnes**\n",
    "\n",
    "Wat is er aan de hand?\n",
    "\n",
    "- Class 3 komt er niet goed uit. Waar de andere klasses (0tm2) tussen 0.862 en 0.915 goed voorspellen, komt dit bij klasse 3 op 0,6 en wordt deze ook vaak verward met klasse 2.\n",
    "- Dit komt door de ongebalanceerde traindataset\n",
    "- Zie daarvoor ook antwoord vraag 1\n",
    "- Wat je kan doen om het te verbeteren: Smooth, Oversampling/Undersampling, Metrics wijzigen (geen accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Tune the model\n",
    "Don't overdo this.\n",
    "More is not better.\n",
    "\n",
    "Bonus points for things like:\n",
    "- Attention layers\n",
    "- Trax architecture including a functioning training loop\n",
    "\n",
    "Keep it small! It's better to present 2 or 3 sane experiments that are structured and thought trough, than 25 random guesses. You can test more, but select 2 or 3 of the best alternatives you researched, with a rationale why this works better.\n",
    "\n",
    "Keep it concise; explain:\n",
    "- what you changed\n",
    "- why you thought that was a good idea  \n",
    "- what the impact was (visualise or numeric)\n",
    "- explain the impact\n",
    "\n",
    "You dont need to get a perfect score; curiousity driven research that fails is fine.\n",
    "The insight into what is happening is more important than the quantity.\n",
    "\n",
    "Keep logs of your settings;\n",
    "either use gin, or save configs, or both :)\n",
    "Store images in the `figures` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-05 20:12:20.404 | INFO     | src.data.data_tools:dir_add_timestamp:68 - Logging to ../tune/20220705-2012\n",
      "100%|██████████| 25/25 [00:02<00:00, 10.16it/s]\n",
      "2022-07-05 20:12:23.572 | INFO     | src.training.train_model:trainloop:164 - Epoch 0 train 1.2950 test 1.2826 metric ['0.1807', '0.7670', '0.2886', '0.3387']\n",
      "100%|██████████| 25/25 [00:02<00:00, 12.49it/s]\n",
      "2022-07-05 20:12:26.063 | INFO     | src.training.train_model:trainloop:164 - Epoch 1 train 1.2396 test 1.1817 metric ['0.2985', '0.6368', '0.3681', '0.4150']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.03it/s]\n",
      "2022-07-05 20:12:27.898 | INFO     | src.training.train_model:trainloop:164 - Epoch 2 train 1.1778 test 1.1304 metric ['0.3082', '0.6994', '0.3961', '0.4688']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.24it/s]\n",
      "2022-07-05 20:12:29.742 | INFO     | src.training.train_model:trainloop:164 - Epoch 3 train 1.0592 test 0.9585 metric ['0.3654', '0.7791', '0.4723', '0.5663']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.71it/s]\n",
      "2022-07-05 20:12:31.546 | INFO     | src.training.train_model:trainloop:164 - Epoch 4 train 0.9612 test 0.8632 metric ['0.4272', '0.7164', '0.4812', '0.5900']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.87it/s]\n",
      "2022-07-05 20:12:33.372 | INFO     | src.training.train_model:trainloop:164 - Epoch 5 train 0.8945 test 0.8232 metric ['0.4993', '0.7431', '0.5351', '0.6425']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.59it/s]\n",
      "2022-07-05 20:12:35.064 | INFO     | src.training.train_model:trainloop:164 - Epoch 6 train 0.8443 test 0.8067 metric ['0.5632', '0.7814', '0.5812', '0.6887']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.23it/s]\n",
      "2022-07-05 20:12:36.779 | INFO     | src.training.train_model:trainloop:164 - Epoch 7 train 0.7288 test 0.6201 metric ['0.6432', '0.8226', '0.6588', '0.7675']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.82it/s]\n",
      "2022-07-05 20:12:38.712 | INFO     | src.training.train_model:trainloop:164 - Epoch 8 train 0.5861 test 0.5140 metric ['0.6816', '0.7456', '0.7365', '0.8125']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.78it/s]\n",
      "2022-07-05 20:12:40.523 | INFO     | src.training.train_model:trainloop:164 - Epoch 9 train 0.5748 test 0.5072 metric ['0.6758', '0.7720', '0.6888', '0.8250']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.90it/s]\n",
      "2022-07-05 20:12:42.452 | INFO     | src.training.train_model:trainloop:164 - Epoch 10 train 0.5371 test 0.4840 metric ['0.6866', '0.8705', '0.7064', '0.8287']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.57it/s]\n",
      "2022-07-05 20:12:44.292 | INFO     | src.training.train_model:trainloop:164 - Epoch 11 train 0.4766 test 0.5235 metric ['0.6929', '0.8336', '0.7086', '0.8200']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.79it/s]\n",
      "2022-07-05 20:12:45.987 | INFO     | src.training.train_model:trainloop:164 - Epoch 12 train 0.4667 test 0.4558 metric ['0.6958', '0.8430', '0.7191', '0.8438']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.75it/s]\n",
      "2022-07-05 20:12:47.816 | INFO     | src.training.train_model:trainloop:164 - Epoch 13 train 0.4782 test 0.4560 metric ['0.6729', '0.8477', '0.7115', '0.8363']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.59it/s]\n",
      "2022-07-05 20:12:49.493 | INFO     | src.training.train_model:trainloop:164 - Epoch 14 train 0.4596 test 0.4712 metric ['0.7197', '0.8016', '0.7395', '0.8213']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.38it/s]\n",
      "2022-07-05 20:12:51.299 | INFO     | src.training.train_model:trainloop:164 - Epoch 15 train 0.3764 test 0.4400 metric ['0.7396', '0.7939', '0.7469', '0.8462']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.09it/s]\n",
      "2022-07-05 20:12:53.114 | INFO     | src.training.train_model:trainloop:164 - Epoch 16 train 0.3757 test 0.3879 metric ['0.7048', '0.8703', '0.7237', '0.8450']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.84it/s]\n",
      "2022-07-05 20:12:54.853 | INFO     | src.training.train_model:trainloop:164 - Epoch 17 train 0.3377 test 0.3875 metric ['0.7563', '0.7871', '0.7953', '0.8588']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.59it/s]\n",
      "2022-07-05 20:12:56.640 | INFO     | src.training.train_model:trainloop:164 - Epoch 18 train 0.4066 test 0.3563 metric ['0.7875', '0.8179', '0.8240', '0.8712']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.29it/s]\n",
      "2022-07-05 20:12:58.355 | INFO     | src.training.train_model:trainloop:164 - Epoch 19 train 0.3284 test 0.4332 metric ['0.7403', '0.8526', '0.7657', '0.8462']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.25it/s]\n",
      "2022-07-05 20:13:00.246 | INFO     | src.training.train_model:trainloop:164 - Epoch 20 train 0.3339 test 0.4967 metric ['0.7310', '0.7881', '0.7548', '0.8075']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.51it/s]\n",
      "2022-07-05 20:13:01.968 | INFO     | src.training.train_model:trainloop:164 - Epoch 21 train 0.3467 test 0.4145 metric ['0.7434', '0.8112', '0.7690', '0.8500']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.32it/s]\n",
      "2022-07-05 20:13:03.689 | INFO     | src.training.train_model:trainloop:164 - Epoch 22 train 0.3063 test 0.3604 metric ['0.7784', '0.8176', '0.8138', '0.8675']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.95it/s]\n",
      "2022-07-05 20:13:05.429 | INFO     | src.training.train_model:trainloop:164 - Epoch 23 train 0.2718 test 0.3708 metric ['0.8134', '0.8652', '0.8184', '0.8712']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.02it/s]\n",
      "2022-07-05 20:13:07.437 | INFO     | src.training.train_model:trainloop:164 - Epoch 24 train 0.2922 test 0.3542 metric ['0.8106', '0.8554', '0.8307', '0.8775']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.87it/s]\n",
      "2022-07-05 20:13:09.187 | INFO     | src.training.train_model:trainloop:164 - Epoch 25 train 0.3294 test 0.3417 metric ['0.7842', '0.8368', '0.8164', '0.8762']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.18it/s]\n",
      "2022-07-05 20:13:10.994 | INFO     | src.training.train_model:trainloop:164 - Epoch 26 train 0.3445 test 0.3424 metric ['0.8144', '0.8621', '0.8225', '0.8812']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.10it/s]\n",
      "2022-07-05 20:13:13.026 | INFO     | src.training.train_model:trainloop:164 - Epoch 27 train 0.2719 test 0.3032 metric ['0.8141', '0.8522', '0.8477', '0.8988']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.49it/s]\n",
      "2022-07-05 20:13:14.963 | INFO     | src.training.train_model:trainloop:164 - Epoch 28 train 0.3185 test 0.3530 metric ['0.7888', '0.8241', '0.8408', '0.8775']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.24it/s]\n",
      "2022-07-05 20:13:16.964 | INFO     | src.training.train_model:trainloop:164 - Epoch 29 train 0.3418 test 0.3052 metric ['0.8176', '0.8545', '0.8344', '0.8888']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.15it/s]\n",
      "2022-07-05 20:13:18.921 | INFO     | src.training.train_model:trainloop:164 - Epoch 30 train 0.3184 test 0.3018 metric ['0.8156', '0.8432', '0.8526', '0.8962']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.94it/s]\n",
      "2022-07-05 20:13:20.778 | INFO     | src.training.train_model:trainloop:164 - Epoch 31 train 0.2524 test 0.3462 metric ['0.8427', '0.8627', '0.8597', '0.8788']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.47it/s]\n",
      "2022-07-05 20:13:22.521 | INFO     | src.training.train_model:trainloop:164 - Epoch 32 train 0.2195 test 0.3110 metric ['0.8279', '0.8442', '0.8781', '0.8875']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.92it/s]\n",
      "2022-07-05 20:13:24.318 | INFO     | src.training.train_model:trainloop:164 - Epoch 33 train 0.1913 test 0.3161 metric ['0.8169', '0.8479', '0.8448', '0.8938']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.92it/s]\n",
      "2022-07-05 20:13:26.089 | INFO     | src.training.train_model:trainloop:164 - Epoch 34 train 0.1668 test 0.3438 metric ['0.7988', '0.7988', '0.8742', '0.8825']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.54it/s]\n",
      "2022-07-05 20:13:27.930 | INFO     | src.training.train_model:trainloop:164 - Epoch 35 train 0.1977 test 0.2872 metric ['0.8389', '0.8547', '0.8645', '0.9038']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.54it/s]\n",
      "2022-07-05 20:13:29.869 | INFO     | src.training.train_model:trainloop:164 - Epoch 36 train 0.1628 test 0.3628 metric ['0.8028', '0.8321', '0.8505', '0.8825']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.55it/s]\n",
      "2022-07-05 20:13:31.633 | INFO     | src.training.train_model:trainloop:164 - Epoch 37 train 0.2075 test 0.3487 metric ['0.7979', '0.8185', '0.8361', '0.8675']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.18it/s]\n",
      "2022-07-05 20:13:33.346 | INFO     | src.training.train_model:trainloop:164 - Epoch 38 train 0.2097 test 0.3294 metric ['0.8306', '0.8783', '0.8578', '0.8962']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.56it/s]\n",
      "2022-07-05 20:13:35.215 | INFO     | src.training.train_model:trainloop:164 - Epoch 39 train 0.1583 test 0.2777 metric ['0.8165', '0.8738', '0.8339', '0.9038']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.93it/s]\n",
      "2022-07-05 20:13:37.015 | INFO     | src.training.train_model:trainloop:164 - Epoch 40 train 0.1965 test 0.3162 metric ['0.8187', '0.8356', '0.8402', '0.8712']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.63it/s]\n",
      "2022-07-05 20:13:38.905 | INFO     | src.training.train_model:trainloop:164 - Epoch 41 train 0.1586 test 0.3441 metric ['0.7961', '0.8161', '0.8709', '0.8825']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.53it/s]\n",
      "2022-07-05 20:13:40.767 | INFO     | src.training.train_model:trainloop:164 - Epoch 42 train 0.1457 test 0.3453 metric ['0.8346', '0.8398', '0.8807', '0.8925']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.20it/s]\n",
      "2022-07-05 20:13:42.485 | INFO     | src.training.train_model:trainloop:164 - Epoch 43 train 0.2221 test 0.3618 metric ['0.7934', '0.8053', '0.8616', '0.8775']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.36it/s]\n",
      "2022-07-05 20:13:44.377 | INFO     | src.training.train_model:trainloop:164 - Epoch 44 train 0.2143 test 0.4005 metric ['0.7840', '0.8494', '0.7925', '0.8475']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.19it/s]\n",
      "2022-07-05 20:13:46.244 | INFO     | src.training.train_model:trainloop:164 - Epoch 45 train 0.1789 test 0.2981 metric ['0.8404', '0.8413', '0.8850', '0.8975']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.79it/s]\n",
      "2022-07-05 20:13:48.200 | INFO     | src.training.train_model:trainloop:164 - Epoch 46 train 0.1832 test 0.3128 metric ['0.8023', '0.8158', '0.8435', '0.8825']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.00it/s]\n",
      "2022-07-05 20:13:50.028 | INFO     | src.training.train_model:trainloop:164 - Epoch 47 train 0.1924 test 0.3033 metric ['0.8016', '0.8436', '0.8422', '0.8938']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.21it/s]\n",
      "2022-07-05 20:13:51.834 | INFO     | src.training.train_model:trainloop:164 - Epoch 48 train 0.1271 test 0.3313 metric ['0.8265', '0.8267', '0.8801', '0.8888']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.94it/s]\n",
      "2022-07-05 20:13:53.614 | INFO     | src.training.train_model:trainloop:164 - Epoch 49 train 0.1027 test 0.3196 metric ['0.8254', '0.8406', '0.8900', '0.8925']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.25it/s]\n",
      "2022-07-05 20:13:55.492 | INFO     | src.training.train_model:trainloop:164 - Epoch 50 train 0.0741 test 0.3486 metric ['0.8519', '0.8464', '0.8906', '0.8888']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.84it/s]\n",
      "2022-07-05 20:13:57.337 | INFO     | src.training.train_model:trainloop:164 - Epoch 51 train 0.1072 test 0.3619 metric ['0.8359', '0.8481', '0.8778', '0.8825']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.96it/s]\n",
      "2022-07-05 20:13:59.285 | INFO     | src.training.train_model:trainloop:164 - Epoch 52 train 0.0842 test 0.3230 metric ['0.8268', '0.8415', '0.8724', '0.9038']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.41it/s]\n",
      "2022-07-05 20:14:01.068 | INFO     | src.training.train_model:trainloop:164 - Epoch 53 train 0.0802 test 0.3365 metric ['0.8211', '0.8416', '0.8740', '0.8912']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.97it/s]\n",
      "2022-07-05 20:14:02.880 | INFO     | src.training.train_model:trainloop:164 - Epoch 54 train 0.0973 test 0.3411 metric ['0.8202', '0.8371', '0.8828', '0.8912']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.25it/s]\n",
      "2022-07-05 20:14:04.660 | INFO     | src.training.train_model:trainloop:164 - Epoch 55 train 0.1456 test 0.3341 metric ['0.8208', '0.8756', '0.8388', '0.8950']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.96it/s]\n",
      "2022-07-05 20:14:06.465 | INFO     | src.training.train_model:trainloop:164 - Epoch 56 train 0.1343 test 0.3289 metric ['0.8036', '0.8486', '0.8315', '0.8775']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.77it/s]\n",
      "2022-07-05 20:14:08.299 | INFO     | src.training.train_model:trainloop:164 - Epoch 57 train 0.1270 test 0.3119 metric ['0.8376', '0.8605', '0.8788', '0.9038']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.30it/s]\n",
      "2022-07-05 20:14:10.189 | INFO     | src.training.train_model:trainloop:164 - Epoch 58 train 0.1347 test 0.3016 metric ['0.8309', '0.8435', '0.8665', '0.9025']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.13it/s]\n",
      "2022-07-05 20:14:12.052 | INFO     | src.training.train_model:trainloop:164 - Epoch 59 train 0.0933 test 0.3044 metric ['0.8360', '0.8436', '0.8855', '0.9000']\n",
      "100%|██████████| 60/60 [01:51<00:00,  1.86s/it]\n"
     ]
    }
   ],
   "source": [
    "from src.models import rnn\n",
    "\n",
    "config = {\n",
    "    \"vocab\": len(v),\n",
    "    \"input_size\": 32,\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 3,\n",
    "    \"dropout\": 0.05,\n",
    "    \"output_size\": 4,\n",
    "}\n",
    "\n",
    "model = rnn.NLPmodel(config)\n",
    "\n",
    "from src.training import train_model\n",
    "\n",
    "model = train_model.trainloop(\n",
    "    epochs=60,\n",
    "    model=model,\n",
    "    metrics=metrics,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    learning_rate=1e-3,\n",
    "    loss_fn=loss_fn,\n",
    "    train_dataloader=trainstreamer,\n",
    "    test_dataloader=teststreamer,\n",
    "    log_dir=log_dir,\n",
    "    train_steps=25,\n",
    "    eval_steps=25,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ik heb het model op verschillende manier getuned en vastgesteld dat de volgende setup het beste werkt (op de waarden die ik getest heb):\n",
    "\n",
    "epochs = 60\n",
    "optimizer = Adam\n",
    "learing_rate = 1e-3\n",
    "drop_out = 0.05\n",
    "\n",
    "De bevindingen en grafieken zijn te vinden onder 'figures'\n",
    "De tunelogs zijn te vinden onder 'logs'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('exam-22-DDG3aTJy-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ef7eee7c1ffccdb050f8336de9a04a9ab88c4d3eb3bee3e0a27c87a184d1d38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
